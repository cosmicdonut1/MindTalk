{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0oHfppytFljq"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'generate' from 'elevenlabs' (c:\\Users\\iamth\\Desktop\\Kaho\\venv\\lib\\site-packages\\elevenlabs\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01melevenlabs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate, play, set_api_key\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'generate' from 'elevenlabs' (c:\\Users\\iamth\\Desktop\\Kaho\\venv\\lib\\site-packages\\elevenlabs\\__init__.py)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from elevenlabs import generate, play, set_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QnfegjM5BrIc"
      },
      "outputs": [],
      "source": [
        "# Function to get a GPT-3 chat response for a given message\n",
        "def get_gpt3_chat_response(state):\n",
        "\n",
        "    # Replace with your actual OpenAI and ElevenLabs API keys\n",
        "    openai_api_key = \"your key\"\n",
        "    # elevenlabs_api_key = \"your key\"\n",
        "    # set_api_key(elevenlabs_api_key)\n",
        "\n",
        "    # Initialize the OpenAI client with your API key\n",
        "    client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "    message = \"I am distracted\"\n",
        "    # print(state)\n",
        "    if state == 1:\n",
        "\n",
        "        # Check if the conversation history exists\n",
        "        if os.path.exists(\"conversation_history.txt\"):\n",
        "            with open(\"conversation_history.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "                history = file.read()\n",
        "        else:\n",
        "            history = \"\"\n",
        "\n",
        "        # Append the current message to the conversation history\n",
        "        conversation_history = f\"{history}\\nUser: {message}\"\n",
        "\n",
        "        chat_response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",  # Replace with the model you want to use\n",
        "            messages=[\n",
        "                {\"role\": \"system\",\n",
        "                 \"content\": \"Your goal is to gently remind the user to concentrate on meditation if he gets distracted. Make your answer short. More stupid jokes. Always answer in English, regardless of the user's language\"},\n",
        "                {\"role\": \"user\", \"content\": conversation_history},\n",
        "            ],\n",
        "            max_tokens=100,\n",
        "        )\n",
        "\n",
        "        # Save the updated conversation history\n",
        "        with open(\"conversation_history.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(f\"{conversation_history}\\nAI: {chat_response.choices[0].message.content.strip()}\")\n",
        "        print(\"GPT-3 response:\", chat_response.choices[0].message.content)\n",
        "        # if chat_response:\n",
        "            # text_to_speech_and_play(chat_response.choices[0].message.content)\n",
        "        # else:\n",
        "            # print(\"No response generated.\")\n",
        "        return chat_response.choices[0].message.content.strip()\n",
        "    else:\n",
        "        return 3\n",
        "\n",
        "\n",
        "# Function to convert text to audio and play it\n",
        "def text_to_speech_and_play(text):\n",
        "    # Check if the \"AI: \" prefix is present\n",
        "    if text.startswith(\"AI: \"):\n",
        "        # Remove the \"AI: \" prefix before sending to text-to-speech\n",
        "        text_without_prefix = text[len(\"AI: \"):]\n",
        "    else:\n",
        "        text_without_prefix = text\n",
        "\n",
        "    # audio_bytes = generate(\n",
        "    #     text=text_without_prefix,\n",
        "    #     voice=\"3wZbmt7q1ZGa1v0w9nvu\",  # meditation\n",
        "    #     # Other parameters as needed\n",
        "    # )\n",
        "    # play(\n",
        "    #     audio=audio_bytes,  # Audio bytes to play\n",
        "    #     # Other parameters as needed\n",
        "    # )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Dog_4puU3fza"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: distracted\n",
            "GPT-3 response: Hey there! It's alright to get distracted, just like a squirrel looking for a nut. Let's refocus on your meditation. Keep calm and meditate on! üêøÔ∏èüßò‚Äç‚ôÇÔ∏è\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n",
            "Current mental State: relaxed\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('bandpower_sample_60s_hybrid.csv')\n",
        "shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Specify the columns to pick\n",
        "columns_to_pick = [25, 27, 33, 35, 41, 43]\n",
        "\n",
        "# Select only the specified columns\n",
        "selected_columns = shuffled_df.iloc[:, columns_to_pick]\n",
        "\n",
        "columns_names = ['blc1','blc3','bmc1','bmc3','bhc1','bhc3']\n",
        "\n",
        "selected_columns.columns = columns_names\n",
        "selected_columns\n",
        "\n",
        "#Calculate total number of rows and seconds\n",
        "total_rows = len(selected_columns)\n",
        "total_seconds = total_rows // 100  # Assuming sampling rate is 250 Hz\n",
        "\n",
        "def classify_mental_state(avg_value):\n",
        "    return \"relaxed\" if avg_value <= 11 else \"distracted\"\n",
        "\n",
        "for second in range(total_seconds):\n",
        "    start_row = second * 100  # Start row for each second\n",
        "    end_row = start_row + 100  # End row for each second (20 rows for 1 second)\n",
        "\n",
        "    # Select the rows for the current second\n",
        "    rows_for_second = selected_columns.iloc[start_row:end_row]\n",
        "\n",
        "    # Calculate average values for each column\n",
        "    avg_value = rows_for_second['blc1'].mean()\n",
        "\n",
        "    # Classify mental state based on the average value\n",
        "    if second == 25 or second == 60:\n",
        "        mental_state = \"distracted\"\n",
        "    else:\n",
        "        mental_state = classify_mental_state(avg_value)\n",
        "\n",
        "    # Print average value and classified mental state\n",
        "    # print(f\"Second {second + 1}:\")\n",
        "    # print(\"Average beta value:\", avg_value)\n",
        "    print(\"Current mental State:\", mental_state)\n",
        "\n",
        "    if mental_state == \"distracted\":\n",
        "        get_gpt3_chat_response(1)\n",
        "    else:\n",
        "        get_gpt3_chat_response(0)\n",
        "\n",
        "    # Sleep for 5 second\n",
        "    time.sleep(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
